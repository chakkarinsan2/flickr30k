{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chakkarinsan2/flickr30k/blob/main/clip_exfeature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7vUesqu2GFeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e594032-e614-46b7-9329-b9f5df6fcd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-15 13:49:23--  https://github.com/chakkarinsan2/flickr30k/releases/download/exfeature/requirements.txt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/543654908/48b1f99b-a4e8-4ea9-a8d6-d0f076fef934?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221015%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221015T134924Z&X-Amz-Expires=300&X-Amz-Signature=8ff13b21cdab604a7bc3b5b1141ce83b44b5b04494d52ecc9a17306755b2f0f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=543654908&response-content-disposition=attachment%3B%20filename%3Drequirements.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-15 13:49:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/543654908/48b1f99b-a4e8-4ea9-a8d6-d0f076fef934?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221015%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221015T134924Z&X-Amz-Expires=300&X-Amz-Signature=8ff13b21cdab604a7bc3b5b1141ce83b44b5b04494d52ecc9a17306755b2f0f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=543654908&response-content-disposition=attachment%3B%20filename%3Drequirements.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 502 [application/octet-stream]\n",
            "Saving to: ‘flickr30k/requirements.txt’\n",
            "\n",
            "flickr30k/requireme 100%[===================>]     502  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-15 13:49:24 (21.7 MB/s) - ‘flickr30k/requirements.txt’ saved [502/502]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# สร้างโฟลเดอร์ชื่อ xxx เพื่อ mount drive จาก google drive ให้ไปทำงานใน google colab\n",
        "!mkdir flickr30k\n",
        "!mkdir semantic_features # สร้างไว้เก็บไฟล์ semantic_feature.npy ที่ได้จากการสกัดคุณลักษณะเชิงความหมาย\n",
        "\n",
        "# โหลด file requirements.txt list python libray ที่ใช้ในการวิเคราะห์และแสดงรูปภาพ \n",
        "if not Path('flickr30k/requirements.txt').exists():\n",
        "  !wget https://github.com/chakkarinsan2/flickr30k/releases/download/exfeature/requirements.txt -O flickr30k/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN7ipbxSGHpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78f2de3-89a6-4e9a-dde1-f86629ac3bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 2)) (4.4.2)\n",
            "Collecting ipykernel==5.4.3\n",
            "  Downloading ipykernel-5.4.3-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting ipython==7.19.0\n",
            "  Downloading ipython-7.19.0-py3-none-any.whl (784 kB)\n",
            "\u001b[K     |████████████████████████████████| 784 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 5)) (0.2.0)\n",
            "Collecting jedi==0.18.0\n",
            "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting jupyter-client==6.1.11\n",
            "  Downloading jupyter_client-6.1.11-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 56.6 MB/s \n",
            "\u001b[?25hCollecting jupyter-core==4.7.0\n",
            "  Downloading jupyter_core-4.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting parso==0.8.1\n",
            "  Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 10)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 11)) (0.7.5)\n",
            "Collecting prompt-toolkit==3.0.10\n",
            "  Downloading prompt_toolkit-3.0.10-py3-none-any.whl (355 kB)\n",
            "\u001b[K     |████████████████████████████████| 355 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 13)) (0.7.0)\n",
            "Collecting Pygments==2.7.4\n",
            "  Downloading Pygments-2.7.4-py3-none-any.whl (950 kB)\n",
            "\u001b[K     |████████████████████████████████| 950 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 60.4 MB/s \n",
            "\u001b[?25hCollecting pyzmq==21.0.1\n",
            "  Downloading pyzmq-21.0.1-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 17)) (1.15.0)\n",
            "Collecting tornado==6.1\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 47.2 MB/s \n",
            "\u001b[?25hCollecting traitlets==5.0.5\n",
            "  Downloading traitlets-5.0.5-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/flickr30k/requirements.txt (line 20)) (0.2.5)\n",
            "Collecting python-dotenv==0.15.0\n",
            "  Downloading python_dotenv-0.15.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting ipyplot==1.1.0\n",
            "  Downloading ipyplot-1.1.0-py3-none-any.whl (13 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |█████████████▋                  | 331.0 MB 1.4 MB/s eta 0:05:24"
          ]
        }
      ],
      "source": [
        "# ติดตั้ง python libray\n",
        "! pip install -r /content/flickr30k/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJCtyZ-THH39"
      },
      "outputs": [],
      "source": [
        "# จำลองตัวแบบ clip จาก github  มาใช้ในการเรียนรู้\n",
        "!git clone https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE3O3FqtJVqP"
      },
      "outputs": [],
      "source": [
        "# โหลด zip file รูปภาพ\n",
        "if not Path('flickr30k/flickr30k_images01.zip').exists():\n",
        "  !wget https://github.com/chakkarinsan2/flickr30k/releases/download/exfeature/flickr30k_images01.zip -O flickr30k/flickr30k_images01.zip\n",
        "\n",
        "if not Path('flickr30k/flickr30k_images02.zip').exists():\n",
        "  !wget https://github.com/chakkarinsan2/flickr30k/releases/download/exfeature/flickr30k_images02.zip -O flickr30k/flickr30k_images02.zip\n",
        "\n",
        "if not Path('flickr30k/flickr30k_images03.zip').exists():\n",
        "  !wget https://github.com/chakkarinsan2/flickr30k/releases/download/exfeature/flickr30k_images03.zip -O flickr30k/flickr30k_images03.zip  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAm_jA3uK8MC"
      },
      "outputs": [],
      "source": [
        "# แตก zip รูปภาพเก็บไว้ที่ -d directory (โฟลเดอร์  flickr30k_images)\n",
        "\n",
        "!unzip \"/content/flickr30k/flickr30k_images01.zip\" -d \"/content/flickr30k/flickr30k_images\"\n",
        "\n",
        "!unzip \"/content/flickr30k/flickr30k_images02.zip\" -d \"/content/flickr30k/flickr30k_images\"\n",
        "\n",
        "!unzip \"/content/flickr30k/flickr30k_images03.zip\" -d \"/content/flickr30k/flickr30k_images\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br40qbYEHy3d"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"flickr30k\")  # กำหนด path เพื่อให้สะดวกต่อการเรียกใช้"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# กำหนด path ของรูปภาพ\n",
        "image_path = (path / \"flickr30k_images\" )\n",
        "\n",
        "# แสดงรายการรูปภาพทั้งหมดในโฟลเดอร์ flickr30k_images\n",
        "image_files = list(image_path.glob(\"*.jpg\"))\n",
        "# print(image_files) # แสดงรายชื่อรูปภาพในโฟลเดอร์\n",
        "\n",
        "print(f\"จำนวนรูปภาพทั้งหมด = {len(image_files)}\") # ที่จะนำไปสกัดคุณลักษณะเชิงความหมาย"
      ],
      "metadata": {
        "id": "7AVygQubqwC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "1mxif3nW4rCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip # โหลดตัวแบบ clip\n",
        "import torch # โหลด library torch\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device) # ใช้โมเดลรุ่น vit-b/32\n",
        "\n",
        "# สร้างฟังค์ชันสกัดเวกเตอร์คุณลักษณะของรูปภาพ \n",
        "def compute_semantic_features(image_batch): # สกัดคุณลักษณะเชิงความหมายด้วยตัวแบบ clip\n",
        "    # เรียกใช้งานรูปภาพทั้งหมด\n",
        "    images = [Image.open(image_file) for image_file in image_batch]\n",
        "    \n",
        "    # วนลูปเพื่อเรียนรู้กับรูปภาพทั้งหมด\n",
        "    images_preprocessed = torch.stack([preprocess(image) for image in images]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # วนลูป encode รูปภาพทั้งหมด เพื่อสกัดเวกเตอร์คุณลักษณะเชิงความหมายของรูปภาพ \n",
        "        images_features = model.encode_image(images_preprocessed)\n",
        "        images_features /= images_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # ผลลัพธ์เป็นเวกเตอร์คุณลักษณะเชิงความหมายของรูปภาพ และ convert to numpy\n",
        "    return images_features.cpu().numpy()"
      ],
      "metadata": {
        "id": "9_7jV3Xzqz2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# กำหนดขนาด batch ในการประมวลผล\n",
        "batch_size = 16\n",
        "\n",
        "# กำหนด path ในการเก็บไฟล์เวกเตอร์คุณลักษณะเชิงความหมายของรูปภาพ ตั้งชื่อว่า features\n",
        "features_path = Path(\"semantic_features\")\n",
        "# ประมวผลตามจำนวน batch size\n",
        "batches = math.ceil(len(image_files) / batch_size)\n",
        "\n",
        "# วนลูปในการประมวลผลเพ่อกระทำกับทุกภาพ\n",
        "for i in range(batches):\n",
        "    print(f\"Processing batch {i+1}/{batches}\")\n",
        "\n",
        "    batch_ids_path = features_path / f\"{i:010d}.csv\"\n",
        "    batch_features_path = features_path / f\"{i:010d}.npy\"\n",
        "    \n",
        "    if not batch_features_path.exists():\n",
        "        try:\n",
        "            batch_files = image_files[i*batch_size : (i+1)*batch_size]\n",
        "\n",
        "            # สกัดเวกเตอร์คุณลักษณะ save เป็น numpy file\n",
        "            batch_features = compute_semantic_features(batch_files)\n",
        "            np.save(batch_features_path, batch_features)\n",
        "\n",
        "            # แยกบันทึก id รูปภาพในไฟล์\n",
        "            image_ids = [photo_file.name.split(\".\")[0] for photo_file in batch_files]\n",
        "            image_ids_data = pd.DataFrame(image_ids, columns=['image_id']) # หัวตารางชื่อ image_id\n",
        "            image_ids_data.to_csv(batch_ids_path, index=False)\n",
        "        except:\n",
        "            # check error\n",
        "            print(f'Problem with batch {i}')\n",
        "        \n",
        "        # batch 1/??? คือจำนวนคุณลักษณะเชิงความหมายที่ตัวแบบ clip คัดแยก"
      ],
      "metadata": {
        "id": "pa83OyzGq449"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# โหลด numpy file ทั้งหมด\n",
        "features_list = [np.load(features_file) for features_file in sorted(features_path.glob(\"*.npy\"))]\n",
        "\n",
        "# เก็บไฟล์จากการสกัดคุณลักษณะเชิงความหมายเป็นเวกเตอร์รูปภาพขนาด 512 float number เป็น semantic_features.npy\n",
        "features = np.concatenate(features_list)\n",
        "np.save(features_path / \"semantic_features.npy\", features)\n",
        "\n",
        "# เก็บไฟล์ id รูปภาพในรูปแบบ csv ชื่อ image_ids.csv\n",
        "image_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(features_path.glob(\"*.csv\"))])\n",
        "image_ids.to_csv(features_path / \"image_ids.csv\", index=False)"
      ],
      "metadata": {
        "id": "_HCiwnpsq8hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Testing**\n",
        "\n",
        "Search image in the Dataset"
      ],
      "metadata": {
        "id": "EG4khj_ApoT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Load the dataset**\n",
        "\n",
        "semantic_features.npy and image_ids.csv\n"
      ],
      "metadata": {
        "id": "WlTrqZQ3pr7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# กำหนด path ในการเรียกใช้ไฟล์คุณลักษณะเชิงความหมายเพื่อ search image\n",
        "features_path = Path(\"semantic_features\") # โฟลเดอร์ที่เก็บไฟล์ semantic_features.npy ที่สกัดมาในขั้นตอนที่แล้ว\n",
        "\n",
        "# อ่านไฟล์รูปภาพในชุดข้อมูลจาก image_id.csv ที่สกัดมาในขั้นตอนที่แล้ว\n",
        "images = pd.read_csv(features_path / \"image_ids.csv\", sep='\\t', header=0) # separate by \\t\n",
        "\n",
        "# โหลดเวกเตอร์คุณลักษณะรูปภาพเชิงความหมายที่สกัดและ id รูปภาพ\n",
        "image_features = np.load(features_path / \"semantic_features.npy\")\n",
        "image_ids = pd.read_csv(features_path / \"image_ids.csv\")\n",
        "image_ids = list(image_ids['image_id']) # กำหนดชื่อรูปภาพที่คอลัมน์ image_id มาแสดงใน ist\n",
        "\n",
        "print(image_features) # ไฟล์คุณลักษณะเชิงความหมาย ที่อยู่ในรูปของ vector เก็บใน array\n",
        "print(image_ids) # ชื่อรูปภาพใน list จาก image_id.csv ที่อยู่ในรูปของ vector เก็บใน array"
      ],
      "metadata": {
        "id": "39NOu9EEn0Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import torch\n",
        "\n",
        "# Load the open CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "metadata": {
        "id": "Wyk0N6Yen3Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search Query**\n",
        "\n",
        "input search query and encode with feature vector using by CLIP.\n"
      ],
      "metadata": {
        "id": "clmzn27LpwTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"play a game\" # search query แบบภาษาธรรมชาติ ในรูปแบบภาษา english เท่านั้น\n",
        "\n",
        "with torch.no_grad():\n",
        "    # encode and normalize search query using CLIP ใช้แทน tranformers\n",
        "    text_encoded = model.encode_text(clip.tokenize(search_query).to(device))\n",
        "    text_encoded /= text_encoded.norm(dim=-1, keepdim=True)\n",
        "\n",
        "print(text_encoded) # ผลจากการเข้ารหัสคุณลักษณะข้อความ เป็นรูปแบบ vector เก็บใน array"
      ],
      "metadata": {
        "id": "-dfgSv3ln6Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vector Matching**\n",
        "\n",
        "matching text features with image features and find the best match."
      ],
      "metadata": {
        "id": "PJWwzlQWpyN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# นำ search query มเข้าสู่ text_encoder แล้วแปลงเป็น numpy เพื่อสร้างคุณลักษณะข้อความ\n",
        "text_features = text_encoded.cpu().numpy()\n",
        "\n",
        "# คำนวณหาค่าความค้ลายคลึงเชิงมุมโคโซน์ระหว่างคุณลักษณะข้อความกับคุณลักษณะรูปภาพ \n",
        "similarities = list((text_features @ image_features.T).squeeze(0))\n",
        "\n",
        "# เรียงลำดับตามค่าความคล้ายคลึงเชิงมุมโคไซน์ เป็น best_images\n",
        "# วนลูปทำการคำนวณทีละรูปจนครบ\n",
        "best_images = sorted(zip(similarities, range(image_features.shape[0])), key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(similarities) # ค่าความคล้ายคลึงเชิงมุมโคไซน์\n",
        "print(best_images) # รูปภาพที่ถูกเรียงลำดับตามค่าความคล้ายคลึงเชิงมุมโคไซน์จากมากไปน้อย ตัีวเลขข้างหลังคือ index ของรูปภาพ"
      ],
      "metadata": {
        "id": "5DROlbIWn8rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Display image**"
      ],
      "metadata": {
        "id": "b4wNZ6Q2p3Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "# วนลูปแสดงผลรูปภาพที่เกี่ยวข้องมากที่สุด 3 อันดับ (range = 3)\n",
        "for i in range(3):\n",
        "    # ค้นคืนรูปภาพที่เกี่ยวข้องมากที่สุดตาม image_id\n",
        "    idx = best_images[i][1]\n",
        "    image_id = image_ids[idx]\n",
        "\n",
        "    # เรียกคืนคุณลักษณะของรูปภาพ (ที่ merge เชิงความหมายไปแล้ว)\n",
        "    image_data = images[images[\"image_id\"] == image_id].iloc[0]\n",
        "    display(image_data)\n",
        "    \n",
        "    # แสดงผลรูปภาพ\n",
        "    show_image = f\"/content/flickr30k/flickr30k_images/{image_id}.jpg\"\n",
        "    display(Image(filename=show_image))"
      ],
      "metadata": {
        "id": "JoXCcSna-5bR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNcHWlI3K7xs41h93w/5wld",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}